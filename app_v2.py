import streamlit as st
import os
import re
import pandas as pd
import time
import json
import httpx

from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.vectorstores import FAISS

# å¯¼å…¥å„å¹³å° LLM å®ç°
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# ========== å¯é€‰ä¾èµ–ï¼ˆç”¨äº Google Sheets è¯»å–ï¼‰ ==========
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GS_AVAILABLE = True
except Exception:
    GS_AVAILABLE = False

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="Impala SQL æ™ºèƒ½åŠ©æ‰‹ Pro", layout="wide", page_icon="ğŸ¤–")

st.markdown("""
<style>
    .stChatMessage {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .stMarkdown h3 {
        color: #4285F4;
        font-size: 1.2rem;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¤– Impala Text-to-SQL æ™ºèƒ½åŠ©æ‰‹ Pro")

# ========== æ ¸å¿ƒï¼šè‡ªåŠ¨è¯†åˆ«å¹¶è·å–æ¨¡å‹åˆ—è¡¨ ==========

def fetch_available_models(api_key):
    """æ ¹æ® API Key è‡ªåŠ¨è¯†åˆ«ä¾›åº”å•†å¹¶æ‹‰å–å¯ç”¨æ¨¡å‹"""
    if not api_key:
        return []

    # 1. è¯†åˆ« Gemini (Google)
    if api_key.startswith("AIza"):
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            models = []
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    models.append({"id": m.name.replace("models/", ""), "provider": "google"})
            return models
        except Exception:
            return []

    # 2. è¯†åˆ« OpenAI å…¼å®¹æ ¼å¼ (Qwen, Kimi, OpenAI ç­‰)
    # é€šç”¨çš„è¯†åˆ«é€»è¾‘ï¼šå°è¯•è¯·æ±‚å…¶æ¨¡å‹åˆ—è¡¨æ¥å£
    providers = {
        "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "kimi": "https://api.moonshot.cn/v1",
        "openai": "https://api.openai.com/v1"
    }
    
    # æ ¹æ® Key ç‰¹å¾æˆ–å°è¯•æ³•
    target_url = providers["openai"] # é»˜è®¤
    current_provider = "openai"
    
    # ç®€å•ç‰¹å¾åˆ¤æ–­
    if "sk-" in api_key:
        # å°è¯•é€šç”¨çš„ OpenAI å…¼å®¹æ¥å£æ‹‰å–
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ä¼˜å…ˆå°è¯•ç”¨æˆ·æœ€å¸¸ç”¨çš„ Qwen å’Œ Kimi
        for name, url in providers.items():
            try:
                response = httpx.get(f"{url}/models", headers={"Authorization": f"Bearer {api_key}"}, timeout=5.0)
                if response.status_code == 200:
                    data = response.json()
                    return [{"id": m["id"], "provider": name} for m in data.get("data", [])]
            except:
                continue
    return []



# ==========================================
# 1. ä¾§è¾¹æ ï¼šæ ¸å¿ƒé…ç½® (API Key & Model)
# ==========================================
with st.sidebar:
    st.header("ğŸ”‘ æ¨¡å‹é…ç½®")
    
    api_key = st.text_input("è¾“å…¥ API Key", type="password", help="æ”¯æŒ Gemini, Qwen, Kimi ç­‰")
    
    # åŠ¨æ€è·å–å¹¶æ˜¾ç¤ºæ¨¡å‹
    available_models = []
    if api_key:
        with st.spinner("æ­£åœ¨è¯†åˆ« Key å¹¶æ‹‰å–æ¨¡å‹..."):
            available_models = fetch_available_models(api_key)
    
    if available_models:
        model_display_names = [f"{m['provider']} | {m['id']}" for m in available_models]
        selected_display = st.selectbox("é€‰æ‹©æ¨¡å‹", model_display_names)
        
        # æå–é€‰ä¸­çš„æ¨¡å‹ä¿¡æ¯
        sel_idx = model_display_names.index(selected_display)
        target_model = available_models[sel_idx]["id"]
        target_provider = available_models[sel_idx]["provider"]
        st.success(f"å·²è¯†åˆ«ä¾›åº”å•†: {target_provider.upper()}")
    else:
        if api_key:
            st.error("æ— æ³•è¯†åˆ«æ­¤ Key æˆ–æ— æ³•è¿æ¥ APIï¼Œè¯·æ£€æŸ¥ç½‘ç»œ")
        st.stop()

    st.divider()



# ==========================================
# 3. åŠ¨æ€åˆå§‹åŒ– LLM å’Œ Embedding
# ==========================================

def get_llm(provider, model_name, api_key):
    if provider == "google":
        return ChatGoogleGenerativeAI(model=model_name, google_api_key=api_key, temperature=0, streaming=True)
    else:
        # Qwen, Kimi ç­‰å‡é€šè¿‡ ChatOpenAI æ¡¥æ¥
        base_urls = {
            "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "kimi": "https://api.moonshot.cn/v1",
            "openai": "https://api.openai.com/v1"
        }
        return ChatOpenAI(
            model=model_name, 
            openai_api_key=api_key, 
            base_url=base_urls.get(provider), 
            temperature=0, 
            streaming=True
        )

def get_embeddings(provider, api_key):
    if provider == "google":
        return GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001", google_api_key=api_key)
    else:
        # æ³¨æ„ï¼šKimi/Qwen çš„ Embedding æ¨¡å‹åä¸åŒï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        # å®é™…ç”Ÿäº§ä¸­å»ºè®®é’ˆå¯¹ provider åˆ¤æ–­å…·ä½“çš„ embedding model å
        emb_model = "text-embedding-v2" if provider == "qwen" else "text-embedding-ada-002"
        base_urls = {
            "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "kimi": "https://api.moonshot.cn/v1",
            "openai": "https://api.openai.com/v1"
        }
        return OpenAIEmbeddings(model=emb_model, openai_api_key=api_key, base_url=base_urls.get(provider))




# ==========================================
# 2. è¾…åŠ©å·¥å…·å‡½æ•°
# ==========================================
def basic_impala_syntax_check(sql_text):
    errors = []
    warnings = []
    if '"' in sql_text and "'" in sql_text:
        warnings.append("âš ï¸ æ£€æµ‹åˆ° SQL ä¸­æ··ç”¨äº†å•å¼•å·å’ŒåŒå¼•å·ï¼ŒImpala ä¸­æ¨èç»Ÿä¸€ä½¿ç”¨å•å¼•å·ã€‚")

    forbidden_funcs = ["getdate()", "to_char(", "sysdate"]
    for func in forbidden_funcs:
        if func.lower() in sql_text.lower():
            errors.append(f"âŒ æ£€æµ‹åˆ°é Impala å…¼å®¹å‡½æ•°: {func}")

    if "sum(" in sql_text.lower() or "count(" in sql_text.lower() or "avg(" in sql_text.lower():
        if "group by" not in sql_text.lower() and "over (" not in sql_text.lower():
            warnings.append("âš ï¸ æ£€æµ‹åˆ°èšåˆå‡½æ•°ä½†æœªå‘ç° GROUP BY æˆ–çª—å£å‡½æ•°ï¼Œè¯·ç¡®è®¤é€»è¾‘æ˜¯å¦æ­£ç¡®ã€‚")

    return errors, warnings

def save_uploaded_file(uploaded_file, dest_path):
    try:
        bytes_data = uploaded_file.read()
        with open(dest_path, "wb") as f:
            f.write(bytes_data)
        return True, None
    except Exception as e:
        return False, str(e)

def gsheet_to_excel_and_save(sheet_id_or_url: str, service_account_info: dict, dest_path: str):
    if not GS_AVAILABLE:
        raise RuntimeError("gspread åº“æœªå®‰è£…")

    scopes = ["https://www.googleapis.com/auth/spreadsheets.readonly",
              "https://www.googleapis.com/auth/drive.readonly"]
    creds = Credentials.from_service_account_info(service_account_info, scopes=scopes)
    gc = gspread.authorize(creds)

    try:
        if sheet_id_or_url.startswith("http"):
            sheet = gc.open_by_url(sheet_id_or_url)
        else:
            sheet = gc.open_by_key(sheet_id_or_url)
    except Exception as e:
        raise e

    writer = pd.ExcelWriter(dest_path, engine="openpyxl")
    for ws in sheet.worksheets():
        values = ws.get_all_values()
        if not values:
            df = pd.DataFrame()
        else:
            df = pd.DataFrame(values)
        df.to_excel(writer, sheet_name=ws.title, index=False, header=False)
    writer.close() # Pandas >= 1.5 ä½¿ç”¨ close() è‡ªåŠ¨ä¿å­˜

# ==========================================
# 3. æ ¸å¿ƒè§£æä¸ç´¢å¼•æ„å»º
# ==========================================
# ç¼“å­˜èµ„æºï¼Œå½“ API Key å˜åŒ–æ—¶éœ€é‡æ–°åŠ è½½ Embedding æ¨¡å‹
@st.cache_resource(show_spinner="æ­£åœ¨æ„å»ºçŸ¥è¯†åº“ç´¢å¼•...")
def init_knowledge_base(api_key,provider):
    # --- å†…éƒ¨è§£æå‡½æ•° ---
    def parse_schema_excel(file_path):
        all_tables = []
        try:
            xl = pd.ExcelFile(file_path)
            for sheet_name in xl.sheet_names:
                try:
                    df_raw = pd.read_excel(xl, sheet_name=sheet_name, header=None)
                    table_name = sheet_name
                    description = "æ— æè¿°"

                    for i in range(min(5, len(df_raw))):
                        row_str = str(df_raw.iloc[i, 0])
                        if "table_name:" in row_str:
                            table_name = row_str.split('table_name:')[-1].strip()
                        elif "description:" in row_str:
                            description = row_str.split('description:')[-1].strip()

                    header_row_index = -1
                    for i, row in df_raw.iterrows():
                        row_values = [str(x) for x in row.values]
                        if "æ–°å­—æ®µ" in row_values:
                            header_row_index = i
                            break

                    if header_row_index == -1: continue

                    df_columns = pd.read_excel(xl, sheet_name=sheet_name, skiprows=header_row_index)
                    df_columns.columns = [str(c).strip() for c in df_columns.columns]

                    columns_list = []
                    for _, row in df_columns.iterrows():
                        if pd.isna(row.get("æ–°å­—æ®µ")): continue
                        field_name = str(row.get('æ–°å­—æ®µ')).strip()
                        field_type = str(row.get('å­—æ®µç±»å‹')).strip() if pd.notna(row.get('å­—æ®µç±»å‹')) else ""
                        field_cn = str(row.get('ä¸­æ–‡å')).strip().replace('\n', ' ') if pd.notna(row.get('ä¸­æ–‡å')) else ""
                        col_info = f"- **{field_name}** ({field_type}): {field_cn}"
                        
                        enum_val = row.get('æšä¸¾å€¼')
                        if pd.notna(enum_val) and str(enum_val).strip() != "":
                            col_info += f" | æšä¸¾: {str(enum_val).strip().replace(chr(10), ' ')}"
                        
                        note_val = row.get('å¤‡æ³¨è¯´æ˜')
                        if pd.notna(note_val) and str(note_val).strip() != "":
                            col_info += f" | âš ï¸å¤‡æ³¨: {str(note_val).strip().replace(chr(10), ' ')}"
                        
                        columns_list.append(col_info)

                    if columns_list:
                        all_tables.append({
                            "table_name": table_name,
                            "description": description,
                            "columns": columns_list
                        })
                except Exception:
                    continue
        except Exception:
            pass
        return all_tables

    def parse_qa_excel(file_path):
        examples = []
        try:
            df = pd.read_excel(file_path, header=None)
            raw_lines = [str(x).strip() for x in df.iloc[:, 0].tolist() if pd.notna(x) and str(x).strip() != '']
            buffer = []
            for line in raw_lines:
                if re.match(r'^ä¾‹\s*\d+[ï¼š:].*', line):
                    if buffer:
                        full_text = "\n".join(buffer)
                        split_match = re.search(r'(.*?)(select\s.*)', full_text, re.IGNORECASE | re.DOTALL)
                        if split_match:
                            examples.append({"question": split_match.group(1).strip(), "sql": split_match.group(2).strip()})
                    buffer = [line]
                else:
                    buffer.append(line)
            if buffer:
                full_text = "\n".join(buffer)
                split_match = re.search(r'(.*?)(select\s.*)', full_text, re.IGNORECASE | re.DOTALL)
                if split_match:
                    examples.append({"question": split_match.group(1).strip(), "sql": split_match.group(2).strip()})
        except Exception:
            pass
        return examples

    if not os.path.exists("table_info_test_v4.xlsx") or not os.path.exists("ç®€å•éœ€æ±‚æ ·ä¾‹.xlsx"):
        return None, None

    schema_data = parse_schema_excel("table_info_test_v4.xlsx")
    qa_data = parse_qa_excel("ç®€å•éœ€æ±‚æ ·ä¾‹.xlsx")

    if not schema_data: return None, None

    schema_docs = [Document(page_content=f"è¡¨å: {t['table_name']}\næè¿°: {t['description']}\nå­—æ®µåˆ—è¡¨:\n" + "\n".join(t['columns']), metadata={"type": "schema"}) for t in schema_data]
    qa_docs = [Document(page_content=q['question'], metadata={"sql": q['sql'], "type": "example"}) for q in qa_data]

    # ä½¿ç”¨ç”¨æˆ·æä¾›çš„ Key åˆå§‹åŒ– Embeddings
    #embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001", google_api_key=api_key_trigger)
    
    # åŠ¨æ€é€‰æ‹© Embedding
    embeddings = get_embeddings(provider, api_key)
    
    #retriever_s = FAISS.from_documents(schema_docs, embeddings).as_retriever(search_kwargs={"k": 10})
    #retriever_e = FAISS.from_documents(qa_docs, embeddings).as_retriever(search_kwargs={"k": 5})
    #return retriever_s, retriever_e
    
    retriever_s = FAISS.from_documents(schema_docs, embeddings).as_retriever(search_kwargs={"k": 10})
    retriever_e = None
    if qa_docs:
        retriever_e = FAISS.from_documents(qa_docs, embeddings).as_retriever(search_kwargs={"k": 5})

    return retriever_s, retriever_e

# ==========================================
# 4. é“¾æ¡é€»è¾‘ (æ¥å—æ¨¡å‹åç§°å’Œ API Key)
# ==========================================
def get_sql_chain(retriever_schema, retriever_examples,provider, model_name, api_key):
    # åŠ¨æ€åˆå§‹åŒ– LLM
    #llm = ChatGoogleGenerativeAI(
    #    model=model_name, 
    #    temperature=0, 
    #    streaming=True,
    #    google_api_key=api_key
    #)
    
    llm = get_llm(provider, model_name, api_key)

    rephrase_template = """åŸºäºå¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„æœ€æ–°é—®é¢˜æ”¹å†™ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ã€åŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡çš„é—®é¢˜ã€‚
    å¯¹è¯å†å²:
    {chat_history}
    æœ€æ–°æé—®: {input}
    ç‹¬ç«‹é—®é¢˜:"""
    rephrase_prompt = ChatPromptTemplate.from_template(rephrase_template)
    rephrase_chain = rephrase_prompt | llm | StrOutputParser()

    sql_template = """ä½ æ˜¯ä¸€ä¸ª Impala SQL ä¸“å®¶åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

    ã€Schema ä¿¡æ¯ (è¡¨ç»“æ„)ã€‘
    {schema}

    ã€å‚è€ƒæ¡ˆä¾‹ (Few-Shot)ã€‘
    {examples}

    ã€ç”¨æˆ·å½“å‰é—®é¢˜ã€‘
    {question}

    è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ€è€ƒå¹¶è¾“å‡ºç»“æœï¼ˆè¯·ä½¿ç”¨ Markdown æ ¼å¼ï¼‰ï¼š

    ### æ­¥éª¤ 1: éœ€æ±‚ä¸å­—æ®µåˆ†æ
    * **åˆ†æ**: ç®€è¿°ä½ å¯¹ç”¨æˆ·éœ€æ±‚çš„ç†è§£ï¼ˆæŒ‡æ ‡ã€ç»´åº¦ã€ç­›é€‰ï¼‰ã€‚
    * **è¡¨ä¸å­—æ®µé€‰æ‹©**: æ˜ç¡®åˆ—å‡ºä½ å†³å®šä½¿ç”¨çš„è¡¨åå’Œå…³é”®å­—æ®µï¼Œå¹¶è§£é‡ŠåŸå› ã€‚
        * æ ¼å¼ï¼š`è¡¨å.å­—æ®µå` (ä¸­æ–‡å) - [ä½¿ç”¨é€»è¾‘]
        * **æ³¨æ„**: å¿…é¡»æ£€æŸ¥å­—æ®µçš„"å¤‡æ³¨è¯´æ˜"å’Œ"æšä¸¾å€¼"ï¼Œç¡®ä¿é€»è¾‘ç¬¦åˆä¸šåŠ¡å®šä¹‰ã€‚

    ### æ­¥éª¤ 2: SQL ç¼–å†™ä¸è‡ªæ£€ (Chain of Thought)
    åœ¨ç¼–å†™ SQL ä¹‹å‰ï¼Œè¯·è¿›è¡Œè‡ªæˆ‘æ£€æŸ¥ï¼š
    * [Check] æ˜¯å¦ä½¿ç”¨äº† Impala å…¼å®¹çš„è¯­æ³•ï¼ˆå•å¼•å·å­—ç¬¦ä¸²ã€Impala æ—¥æœŸå‡½æ•°ï¼‰ï¼Ÿ
    * [Check] æ˜¯å¦å­˜åœ¨å¤šè¡¨è¿æ¥ï¼Ÿè¿æ¥é”®æ˜¯å¦åœ¨ Schema ä¸­å­˜åœ¨ï¼Ÿ
    * [Check] WHERE æ¡ä»¶ä¸­çš„æ—¶é—´èŒƒå›´æ˜¯å¦ç¬¦åˆç”¨æˆ·æè¿°ï¼Ÿ
    * [Check] èšåˆè®¡ç®—ï¼ˆSum/Countï¼‰æ˜¯å¦æ­£ç¡®é…åˆäº† Group Byï¼Ÿ

    ### æ­¥éª¤ 3: SQL ä»£ç 
    è¯·ç”Ÿæˆæœ€ç»ˆçš„ SQL ä»£ç ã€‚
    ```sql
    -- åœ¨è¿™é‡Œå†™ SQL
    ```
    """

    sql_prompt = ChatPromptTemplate.from_template(sql_template)

    def format_docs(docs): return "\n\n".join([d.page_content for d in docs])
    def format_qs(docs): return "\n\n".join([f"Q: {d.page_content}\nSQL: {d.metadata['sql']}" for d in docs])

    chain = (
        RunnablePassthrough.assign(
            standalone_question=lambda x: rephrase_chain.invoke(x) if x.get("chat_history") else x["input"]
        )
        | RunnablePassthrough.assign(
            schema=lambda x: format_docs(retriever_schema.invoke(x["standalone_question"])),
            examples=lambda x: format_qs(retriever_examples.invoke(x["standalone_question"])) if retriever_examples else "",
            question=lambda x: x["standalone_question"]
        )
        | sql_prompt
        | llm
        | StrOutputParser()
    )
    return chain

# ==========================================
# 5. ä¾§è¾¹æ ï¼šçŸ¥è¯†åº“ç®¡ç†é€»è¾‘
# ==========================================
with st.sidebar:
    st.header("ğŸ—‚ï¸ çŸ¥è¯†åº“ç®¡ç†")
    st.caption("é¦–æ¬¡ä½¿ç”¨è¯·å…ˆæ„å»ºçŸ¥è¯†åº“")

    # æ˜¾ç¤ºæ–‡ä»¶çŠ¶æ€
    has_files = os.path.exists("table_info_test_v4.xlsx") and os.path.exists("ç®€å•éœ€æ±‚æ ·ä¾‹.xlsx")
    file_status = "âœ… å·²å°±ç»ª" if has_files else "âŒ ç¼ºå¤±æ–‡ä»¶"
    st.text(f"æœ¬åœ°çŠ¶æ€: {file_status}")

    with st.expander("ğŸ› ï¸ ä¸Šä¼ æˆ–æ›´æ–°çŸ¥è¯†åº“"):
        st.subheader("1. è¡¨ç»“æ„ (Schema)")
        schema_source = st.radio("Schema æ¥æº", ("ä¸Šä¼  Excel", "Google Sheets"), key="s_src")
        
        if schema_source == "ä¸Šä¼  Excel":
            up_schema = st.file_uploader("ä¸Šä¼  table_info_test_v4.xlsx", type=["xlsx"])
            if st.button("ä¿å­˜ Schema Excel") and up_schema:
                save_uploaded_file(up_schema, "table_info_test_v4.xlsx")
                st.success("å·²ä¿å­˜!")
                st.rerun()
        else:
            s_id = st.text_input("Sheet ID/URL", key="s_id")
            s_sa = st.file_uploader("Service Account JSON", type=["json"], key="s_sa")
            if st.button("ä» Sheets åŒæ­¥ Schema") and s_id and s_sa:
                try:
                    sa_info = json.load(s_sa)
                    gsheet_to_excel_and_save(s_id, sa_info, "table_info_test_v4.xlsx")
                    st.success("åŒæ­¥æˆåŠŸ!")
                    st.rerun()
                except Exception as e:
                    st.error(str(e))

        st.divider()
        st.subheader("2. é—®ç­”æ ·ä¾‹ (Few-Shot)")
        qa_source = st.radio("æ ·ä¾‹æ¥æº", ("ä¸Šä¼  Excel", "Google Sheets"), key="q_src")
        
        if qa_source == "ä¸Šä¼  Excel":
            up_qa = st.file_uploader("ä¸Šä¼  ç®€å•éœ€æ±‚æ ·ä¾‹.xlsx", type=["xlsx"])
            if st.button("ä¿å­˜æ ·ä¾‹ Excel") and up_qa:
                save_uploaded_file(up_qa, "ç®€å•éœ€æ±‚æ ·ä¾‹.xlsx")
                st.success("å·²ä¿å­˜!")
                st.rerun()
        else:
            q_id = st.text_input("Sheet ID/URL", key="q_id")
            q_sa = st.file_uploader("Service Account JSON", type=["json"], key="q_sa_f")
            if st.button("ä» Sheets åŒæ­¥æ ·ä¾‹") and q_id and q_sa:
                try:
                    sa_info = json.load(q_sa)
                    gsheet_to_excel_and_save(q_id, sa_info, "ç®€å•éœ€æ±‚æ ·ä¾‹.xlsx")
                    st.success("åŒæ­¥æˆåŠŸ!")
                    st.rerun()
                except Exception as e:
                    st.error(str(e))

    if st.button("ğŸ”„ é‡ç½®/æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

# ==========================================
# 6. ä¸»æµç¨‹ï¼šåˆå§‹åŒ–ä¸å¯¹è¯
# ==========================================
if has_files:
    # ä¼ å…¥ user_api_key ä½œä¸º triggerï¼Œå¦‚æœ key å˜äº†ï¼Œç¼“å­˜å¤±æ•ˆé‡æ–°åŠ è½½
    rs, re_ = init_knowledge_base(api_key,target_provider)
    if rs:
        # è·å–é“¾å¯¹è±¡ï¼Œä¼ å…¥å½“å‰é€‰æ‹©çš„æ¨¡å‹å’Œ API Key
        chain = get_sql_chain(rs, re_, selected_model, api_key)
    else:
        st.warning("çŸ¥è¯†åº“æ–‡ä»¶è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ Excel æ ¼å¼ã€‚")
        st.stop()
else:
    st.info("ğŸ‘‹ æ¬¢è¿ï¼è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼  Excel æ–‡ä»¶æˆ–è¿æ¥ Google Sheets ä»¥æ„å»ºçŸ¥è¯†åº“ã€‚")
    st.stop()

# --- å¯¹è¯ç•Œé¢ ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    avatar = "ğŸ§‘â€ğŸ’»" if role == "user" else "ğŸ¤–"
    with st.chat_message(role, avatar=avatar):
        st.markdown(msg.content)

if prompt := st.chat_input("è¯·è¾“å…¥æŸ¥è¯¢éœ€æ±‚..."):
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(prompt)
    history = st.session_state.messages.copy()

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            stream = chain.stream({
                "input": prompt,
                "chat_history": history
            })

            for chunk in stream:
                full_response += chunk
                message_placeholder.markdown(full_response + "â–Œ")

            message_placeholder.markdown(full_response)

            # SQL è‡ªåŠ¨æ£€æµ‹
            sql_match = re.search(r"```sql\n(.*?)\n```", full_response, re.DOTALL)
            if sql_match:
                sql_code = sql_match.group(1)
                errors, warnings = basic_impala_syntax_check(sql_code)
                if errors or warnings:
                    report = "\n\n---\n**ğŸ” è¯­æ³•è‡ªæ£€:**\n" + "\n".join([f"- {e}" for e in errors + warnings])
                    full_response += report
                    message_placeholder.markdown(full_response)

            st.session_state.messages.append(HumanMessage(content=prompt))
            st.session_state.messages.append(AIMessage(content=full_response))

        except Exception as e:
            st.error(f"âš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")
            st.caption("å»ºè®®æ£€æŸ¥ API Key é¢åº¦æˆ–ç½‘ç»œè¿æ¥ã€‚")